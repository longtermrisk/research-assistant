# Light-RAG

The idea of this repo is to implement a lightweight rag system that is inspired by how attention works: when a document is ingested, we compute a list of "keys", and when documents are being retrieved from a query, we compute the document score as by comparing the query to these keys.

Keys and summaries are generated by prompting an LLM with an Annotator:
> This document is being stored in a RAG database. Your task is to:
> 1. Generate a list of up to {n} hypothetical queries that should retrieve this document (ordered from most to least important)
> 2. Create a concise summary of the document's main content and purpose

(Optionally, additional context can be provided that will also be present at retrieval time.)

# Implementation state
The implementation is in `rag.py`. All three milestones are complete plus the new OpenAI annotator and reranker system:
- MemoryRagStore for in-memory document storage and retrieval
- FileSystemStore with full persistence and serialization
- OpenAI embeddings integration
- Component registry for dynamic loading
- Document ingestion and query functionality
- Basic cosine similarity-based retrieval
- Evaluation framework with batch ingestion and automated testing
- **OpenAiAnnotator with structured outputs for hypothetical query generation and document summarization**
- **NEW: Reranker system with StandardReranker and OpenAiReranker for intelligent document reordering**

Test scripts and examples are available in `tests/test_milestone1.py`, `tests/test_milestone2.py`, `tests/test_milestone3.py`, `tests/example_usage.py`, `example_filesystem.py`, `tests/test_openai_keygen.py`, `example_annotator_demo.py`, `test_reranker.py`, and `example_reranker_demo.py`.

# Milestones

## COMPLETED Milestone 1: MemoryRagStore MVP
Implemented a first version where no additional keys are generated besides the document itself. This works with text-only documents and uses the OpenAI embeddings API.

**Key Features:**
- `Document` class with metadata and content blocks
- `MemoryRagStore` for in-memory storage
- `OpenAIEmbedder` for generating embeddings via OpenAI API
- `NoAdditionalKeys` annotator (uses document content as-is)
- Async-first architecture
- Cosine similarity-based retrieval with top-k ranking
- Full type safety with Pydantic models

**Files:**
- `rag.py`: Core implementation
- `tests/test_milestone1.py`: Basic functionality test
- `example_usage.py`: Interactive demo
- `README.md`: Usage documentation

## COMPLETED Milestone 2: FileSystemStore
Implemented persistent storage with serialization and loading capabilities.

**Key Features:**
- `FileSystemStore` with automatic persistence
- `ComponentRegistry` for dynamic component loading
- `StoreConfig` for serializing store settings
- Methods to save/load embedder and annotator configurations
- Store configuration saved as JSON in root directory
- Document files saved individually with embeddings
- Error handling for missing directories/configs
- Statistics and document management utilities

**Implementation Details:**
- Registry pattern enables loading components by class name and config
- Store configuration includes embedder_id, annotator_id, and their configs
- Documents serialized as individual JSON files with embeddings
- `FileSystemStore.create()` for new stores, `FileSystemStore.load()` for existing
- Inherits from `MemoryRagStore` so all query functionality works the same

**Files:**
- `rag.py`: Updated with FileSystemStore and registry
- `tests/test_milestone2.py`: Persistence functionality test
- `example_filesystem.py`: Interactive persistent demo

## COMPLETED Milestone 3: Evaluation Framework
Implemented comprehensive evaluation framework with batch ingestion, automated testing, and interactive querying.

**Key Features:**
- Batch directory ingestion with parallel file processing
- Automated evaluation using JSON test cases
- Interactive query mode with document source display
- Performance metrics including precision, recall, and ranking analysis
- Command-line interface with argument parsing
- Support for multiple file types (.txt, .md, .py, .js, .html, .css, .json, .yaml, .xml, .csv)

**Implementation Details:**
- `ingest_directory_parallel()` function for efficient batch processing
- `run_evaluation()` function that processes JSON test cases and outputs detailed results
- `interactive_mode()` for real-time querying with source file display
- Evaluation JSON format with test cases, queries, and expected document sources
- Output format includes ranking information, min_top_k metrics, and performance statistics
- ThreadPoolExecutor for parallel file reading
- Batched API calls to avoid rate limiting
- Progress reporting for large directories

**Files:**
- `example_filesystem.py`: Complete evaluation framework implementation
- `tests/test_milestone3.py`: Comprehensive testing of batch ingestion and evaluation
- `sample_eval.json`: Example evaluation test cases
- `README.md`: Updated with Milestone 3 documentation

## NEW: OpenAI Annotator with Structured Outputs
Implemented advanced document annotation using OpenAI's structured outputs API to generate both hypothetical queries and document summaries.

**Key Features:**
- `OpenAiAnnotator` class using OpenAI's structured outputs for reliable query generation and summarization
- Configurable number of keys (n_keys parameter)
- Context-aware annotation (optional context parameter)
- Structured output validation using Pydantic models
- Document summaries stored in metadata
- Error handling with fallback to document content
- Full integration with component registry for persistence

**Implementation Details:**
- Uses `client.beta.chat.completions.parse()` with structured outputs for reliable JSON parsing
- `AnnotationOutput` Pydantic model defines the expected output structure with queries and summary
- Prompt engineering includes context separation and importance ordering
- Always includes original document content as first key for baseline retrieval
- Summaries are automatically added to document metadata during ingestion
- Handles API errors gracefully with fallback behavior
- Supports both gpt-4.1-mini and other compatible models

**Usage Example:**
```python
from rag import OpenAiAnnotator, OpenAIEmbedder, FileSystemStore
from dtypes import TextBlock

# Create annotator with structured outputs
annotator = OpenAiAnnotator(
    model="gpt-4.1-mini", 
    n_keys=10,
    api_key=your_api_key
)

# Use with context for better annotation
context = [TextBlock(text="This is a programming documentation database.")]
store = FileSystemStore.create(
    embedder=OpenAIEmbedder(api_key=your_api_key),
    annotator=annotator,
    root_dir="my_store",
    context=context
)
```

**Files:**
- `rag.py`: Updated with OpenAiAnnotator class
- `tests/test_openai_keygen.py`: Comprehensive testing of annotation
- `example_annotator_demo.py`: Interactive demo with summaries

## NEW: Reranker System
Implemented a comprehensive reranking system that improves document retrieval by intelligently reordering candidates after initial similarity-based retrieval.

**Key Features:**
- `Reranker` abstract base class for pluggable reranking strategies
- `StandardReranker` for simple top-k selection without reordering
- `OpenAiReranker` using OpenAI's structured outputs for intelligent document reranking
- Two-stage retrieval: first retrieve `top_k_retrieval` candidates, then rerank to `top_k` results
- Integration with component registry for persistence and configuration
- Document summaries and sources provided to reranker for better decisions
- Configurable retrieval parameters for balancing performance and quality

**Implementation Details:**
- Rerankers receive query content, candidate documents, and desired top_k count
- `OpenAiReranker` uses structured outputs with `RerankingOutput` Pydantic model
- Reranking prompt includes document sources, titles, summaries, and content previews
- Error handling with fallback to standard reranking on API failures
- `top_k_retrieval` parameter controls the candidate pool size for reranking
- Full backward compatibility with existing stores (defaults to StandardReranker)

**Usage Example:**
```python
from rag import OpenAiReranker, StandardReranker, FileSystemStore

# Create intelligent reranker
reranker = OpenAiReranker(api_key=your_api_key)

# Or use simple reranker
reranker = StandardReranker()

# Create store with reranking
store = FileSystemStore.create(
    embedder=embedder,
    annotator=annotator,
    reranker=reranker,
    root_dir="my_store",
    top_k_retrieval=20  # Retrieve 20 candidates, rerank to top_k
)

# Query returns reranked results
results = await store.query(query, top_k=5)
```

**Files:**
- `rag.py`: Updated with Reranker classes and two-stage retrieval
- `test_reranker.py`: Comprehensive testing of reranking functionality
- `example_reranker_demo.py`: Interactive demo comparing rerankers

## NEW: Automator Hook Integration
Implemented seamless integration with the Automator agent system through a RAG hook that automatically retrieves relevant documents during conversations.

**Key Features:**
- `create_rag_hook()` function for creating configurable RAG hooks
- Automatic document ingestion from specified directories
- Context-aware retrieval using conversation history
- Smart document management with summarization for older/less relevant docs
- Integration with Automator's hook system for seamless agent enhancement
- Configurable retrieval parameters and document limits

**Implementation Details:**
- Hook automatically ingests documents from the specified directory on each query
- Uses conversation history (`thread.messages_after_hooks`) as query context for retrieval
- Maintains document relevance tracking across conversation turns
- Adds full document content for highly relevant docs, summaries for less relevant ones
- Supports configurable `relative_path` (default: `.knowledge`) and `n_retrieved_docs` (default: 10)
- Store caching prevents redundant initialization across hook calls
- Automatic context setting from workspace `LLM.md` file if available

**Usage Example:**
```python
from rag.hook import create_rag_hook
from automator.agent import Agent

# Create a RAG hook for the .knowledge directory
create_rag_hook('.knowledge', n_retrieved_docs=10)

# Use with an Automator agent
agent = Agent(
    model="gpt-4.1",
    prompt_template_yaml="chatgpt.yaml",
    workspace=workspace,
    tools=['terminal.*'],
    hooks=['rag:.knowledge']  # Enable RAG hook
)

# The hook will automatically:
# 1. Ingest documents from workspace/.knowledge/
# 2. Retrieve relevant docs based on conversation context
# 3. Add document content to message history
# 4. Track document relevance across turns
```

**Hook Behavior:**
- Documents are added to conversation history with `<document src="...">` tags
- Most relevant documents include full content
- Less relevant documents show only summaries with note about summarization
- Document metadata is tracked in message meta fields as `rag:{relative_path}`
- Store uses OpenAI components (embedder, annotator, reranker) by default
- Automatic fallback to store creation if no existing store found

**Files:**
- `src/rag/hook.py`: Hook implementation with store management and document retrieval
- `rag_hook_example.py`: Example usage with Automator agent system


# Updating this file
This file serves as an onboarding document for you in the future. Always keep it up-to-date and add important notes to this file.

# Notes

## Milestone 1 Implementation Details
- Used `generalized_mean` with p=2 (quadratic mean) for aggregating multiple key similarities per document
- Implemented proper cosine similarity with vector normalization
- Error handling for empty embeddings and missing content
- Async/await throughout for scalability
- Proper separation of concerns with abstract base classes

## Milestone 2 Implementation Details
- Registry pattern allows dynamic loading of components from configuration
- Store configuration includes all necessary information to recreate the store
- Individual document files enable incremental loading and updates
- Error handling for missing files, corrupted configs, and unknown component types
- Statistics method provides insights into store contents
- FileSystemStore inherits from MemoryRagStore for code reuse

## Milestone 3 Implementation Details
- Parallel file processing using ThreadPoolExecutor for I/O operations
- Batched embedding generation to respect API rate limits
- Comprehensive evaluation metrics including precision@k, recall@k, and min_top_k
- Command-line argument parsing for flexible usage patterns
- Support for both interactive and automated evaluation modes
- Robust error handling for file reading and processing
- Progress reporting for long-running operations

## OpenAI Annotator Implementation Details
- Structured outputs ensure reliable JSON parsing without manual string manipulation
- AnnotationOutput Pydantic model validates the LLM response structure with queries and summary
- Prompt includes clear context separation and importance ordering instructions
- Always includes original document content as the first key for baseline retrieval
- Summaries are automatically added to document metadata during ingestion
- Error handling includes API failures, rate limiting, and malformed responses
- Compatible with component registry for full persistence support
- Uses gpt-4.1-mini as default model

## Automator Hook Implementation Details
- Hook registration uses decorator pattern with `@register_hook(f'rag:{relative_path}')`
- Store caching with `_stores` dictionary prevents redundant initialization
- Document ingestion uses `existing_source='ignore'` to avoid re-processing unchanged files
- Context is automatically set from workspace `LLM.md` file for domain-specific retrieval
- Query uses conversation history (`thread.messages_after_hooks`) for context-aware retrieval
- Document tracking across conversation turns with message metadata
- Smart document management: full content for relevant docs, summaries for older/less relevant ones
- Automatic fallback to store creation if no existing store found in directory

## Key Design Decisions
- ContentBlock system from dtypes.py allows for future multimodal support
- Embedder, Annotator, and Reranker are pluggable via abstract base classes
- Document metadata includes timestamps, source tracking, and scoping
- Store operations are async to support future database backends
- Registry pattern enables extensibility for custom embedders/annotators/rerankers
- Configuration serialization uses Pydantic for type safety and validation
- Evaluation framework designed to be extensible for different metrics and test formats
- Structured outputs provide reliability and type safety for LLM-generated content
- Context parameter enables domain-specific key generation for better retrieval performance
- Summaries provide quick document overviews for improved user experience and understanding
- Two-stage retrieval (similarity + reranking) balances performance and quality
- Reranker system is backward compatible and optional (defaults to StandardReranker)
- Hook system integrates seamlessly with Automator's agent architecture
- Document relevance tracking enables intelligent content management across conversation turns